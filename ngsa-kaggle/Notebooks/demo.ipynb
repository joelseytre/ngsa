{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/adib/Documents/Cours/Projet/NGSA/ngsa/ngsa-kaggle\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from predictor_settings import predictor_settings\n",
    "from predictors.NGSApredictor import NGSApredictor\n",
    "from predictors.svm_baseline import BaselineSVM\n",
    "from predictors.gradboost import Gradboost\n",
    "from predictors.randomforest import RandomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/adib/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/adib/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "predictors\n",
      "\n",
      "\n",
      "Predicting stuff... \n",
      "Training: 615512 \n",
      "Reduced training: 61551 \n",
      "Testing: 32648\n",
      "\n",
      "Read features from stored data!\n"
     ]
    }
   ],
   "source": [
    "svm = BaselineSVM(predictor_settings)\n",
    "svm.load_features(\"stored_training_v3.txt\", \"stored_testing_v3.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM trained with C = 0.01\n",
      "SVM model: F1 score - Training 0.962 - Validation 0.963\n",
      "-----------\n",
      "SVM trained with C = 0.1\n",
      "SVM model: F1 score - Training 0.965 - Validation 0.967\n",
      "-----------\n",
      "SVM trained with C = 1\n",
      "SVM model: F1 score - Training 0.966 - Validation 0.968\n",
      "-----------\n",
      "SVM trained with C = 10\n",
      "SVM model: F1 score - Training 0.966 - Validation 0.968\n",
      "-----------\n",
      "SVM trained with C = 100\n",
      "SVM model: F1 score - Training 0.965 - Validation 0.966\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "for c in [10**i for i in range(-2,3)]:\n",
    "    print \"SVM trained with C =\", c\n",
    "    svm.run(c)\n",
    "    print '-----------'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/adib/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/adib/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "predictors\n",
      "\n",
      "\n",
      "Predicting stuff... \n",
      "Training: 615512 \n",
      "Reduced training: 61551 \n",
      "Testing: 32648\n",
      "\n",
      "Read features from stored data!\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForest(predictor_settings)\n",
    "rf.load_features(\"stored_training_v3.txt\", \"stored_testing_v3.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest trained with 10 trees\n",
      "Random Forest model: F1 score - Training 0.997 - Validation 0.973\n",
      "-----------\n",
      "Random Forest trained with 100 trees\n",
      "Random Forest model: F1 score - Training 1.000 - Validation 0.974\n",
      "-----------\n",
      "Random Forest trained with 1000 trees\n",
      "Random Forest model: F1 score - Training 1.000 - Validation 0.975\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "for n in [10**i for i in range(1,4)]:\n",
    "    print \"Random Forest trained with\", n, 'trees'\n",
    "    rf.run(n,None)\n",
    "    print '-----------'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest trained with 100 trees of depth 5\n",
      "Random Forest model: F1 score - Training 1.000 - Validation 0.975\n",
      "-----------\n",
      "Random Forest trained with 100 trees of depth 10\n",
      "Random Forest model: F1 score - Training 1.000 - Validation 0.975\n",
      "-----------\n",
      "Random Forest trained with 100 trees of depth 15\n",
      "Random Forest model: F1 score - Training 1.000 - Validation 0.975\n",
      "-----------\n",
      "Random Forest trained with 100 trees of depth 20\n",
      "Random Forest model: F1 score - Training 1.000 - Validation 0.974\n",
      "-----------\n",
      "Random Forest trained with 100 trees of depth 25\n",
      "Random Forest model: F1 score - Training 1.000 - Validation 0.975\n",
      "-----------\n",
      "Random Forest trained with 100 trees of depth 30\n",
      "Random Forest model: F1 score - Training 1.000 - Validation 0.975\n",
      "-----------\n",
      "Random Forest trained with 100 trees of depth 35\n",
      "Random Forest model: F1 score - Training 1.000 - Validation 0.975\n",
      "-----------\n",
      "Random Forest trained with 100 trees of depth 40\n",
      "Random Forest model: F1 score - Training 1.000 - Validation 0.975\n",
      "-----------\n",
      "Random Forest trained with 100 trees of depth 45\n",
      "Random Forest model: F1 score - Training 1.000 - Validation 0.975\n",
      "-----------\n",
      "Random Forest trained with 100 trees of depth 50\n",
      "Random Forest model: F1 score - Training 1.000 - Validation 0.975\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "for d in [5*i for i in range(1,11)]:\n",
    "    print \"Random Forest trained with 100 trees of depth\", d\n",
    "    rf.run(100,None)\n",
    "    print '-----------'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/adib/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/adib/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "predictors\n",
      "\n",
      "\n",
      "Predicting stuff... \n",
      "Training: 615512 \n",
      "Reduced training: 61551 \n",
      "Testing: 32648\n",
      "\n",
      "Read features from stored data!\n"
     ]
    }
   ],
   "source": [
    "gb = Gradboost(predictor_settings)\n",
    "gb.load_features(\"stored_training_v3.txt\", \"stored_testing_v3.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradboost with lambda = 0.25\n",
      "Gradboost model: F1 score - Training 0.979 - Validation 0.976\n",
      "-----------\n",
      "Gradboost with lambda = 0.5\n",
      "Gradboost model: F1 score - Training 0.979 - Validation 0.976\n",
      "-----------\n",
      "Gradboost with lambda = 1\n",
      "Gradboost model: F1 score - Training 0.978 - Validation 0.975\n",
      "-----------\n",
      "Gradboost with lambda = 2\n",
      "Gradboost model: F1 score - Training 0.979 - Validation 0.976\n",
      "-----------\n",
      "Gradboost with lambda = 4\n",
      "Gradboost model: F1 score - Training 0.979 - Validation 0.976\n",
      "-----------\n",
      "Gradboost with lambda = 8\n",
      "Gradboost model: F1 score - Training 0.979 - Validation 0.976\n",
      "-----------\n",
      "Gradboost with lambda = 16\n",
      "Gradboost model: F1 score - Training 0.979 - Validation 0.976\n",
      "-----------\n",
      "Gradboost with lambda = 32\n",
      "Gradboost model: F1 score - Training 0.979 - Validation 0.976\n",
      "-----------\n",
      "Gradboost with lambda = 64\n",
      "Gradboost model: F1 score - Training 0.979 - Validation 0.976\n",
      "-----------\n",
      "Gradboost with lambda = 128\n",
      "Gradboost model: F1 score - Training 0.978 - Validation 0.976\n",
      "-----------\n",
      "Gradboost with lambda = 256\n",
      "Gradboost model: F1 score - Training 0.978 - Validation 0.975\n",
      "-----------\n",
      "Gradboost with lambda = 512\n",
      "Gradboost model: F1 score - Training 0.978 - Validation 0.975\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "for lmbda in [2**i for i in range(-2,10)]:\n",
    "    print \"Gradboost with lambda =\", lmbda\n",
    "    gb.run(lmbda)\n",
    "    print '-----------'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/adib/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/adib/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "predictors\n",
      "\n",
      "\n",
      "Predicting stuff... \n",
      "Training: 615512 \n",
      "Reduced training: 61551 \n",
      "Testing: 32648\n",
      "\n",
      "Read features from stored data!\n"
     ]
    }
   ],
   "source": [
    "gb = Gradboost(predictor_settings)\n",
    "gb.load_features(\"stored_training_v3.txt\", \"stored_testing_v3.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_list = ['overlap_title', 'temp_diff', 'comm_auth','tfidf_distance_corpus', 'tfidf_distance_titles',\n",
    "                 'tfidf_distance_authors','num_inc_edges', 'shortest_path_dijkstra',\n",
    "                 'shortest_path_dijkstra_und', 'jaccard_und']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradboost Model with removed features:  ['overlap_title']\n",
      "Gradboost model: F1 score - Training 0.979 - Validation 0.976\n",
      "-----------\n",
      "Gradboost Model with removed features:  ['temp_diff']\n",
      "Gradboost model: F1 score - Training 0.974 - Validation 0.970\n",
      "-----------\n",
      "Gradboost Model with removed features:  ['comm_auth']\n",
      "Gradboost model: F1 score - Training 0.978 - Validation 0.976\n",
      "-----------\n",
      "Gradboost Model with removed features:  ['tfidf_distance_corpus']\n",
      "Gradboost model: F1 score - Training 0.974 - Validation 0.972\n",
      "-----------\n",
      "Gradboost Model with removed features:  ['tfidf_distance_titles']\n",
      "Gradboost model: F1 score - Training 0.978 - Validation 0.975\n",
      "-----------\n",
      "Gradboost Model with removed features:  ['tfidf_distance_authors']\n",
      "Gradboost model: F1 score - Training 0.978 - Validation 0.975\n",
      "-----------\n",
      "Gradboost Model with removed features:  ['num_inc_edges']\n",
      "Gradboost model: F1 score - Training 0.977 - Validation 0.975\n",
      "-----------\n",
      "Gradboost Model with removed features:  ['shortest_path_dijkstra']\n",
      "Gradboost model: F1 score - Training 0.977 - Validation 0.974\n",
      "-----------\n",
      "Gradboost Model with removed features:  ['shortest_path_dijkstra_und']\n",
      "Gradboost model: F1 score - Training 0.978 - Validation 0.974\n",
      "-----------\n",
      "Gradboost Model with removed features:  ['jaccard_und']\n",
      "Gradboost model: F1 score - Training 0.978 - Validation 0.974\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "for feat in features_list:\n",
    "    gb.run_([feat])\n",
    "    print '-----------'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradboost Model with removed features:  ['overlap_title', 'temp_diff', 'comm_auth']\n",
      "Gradboost model: F1 score - Training 0.974 - Validation 0.971\n"
     ]
    }
   ],
   "source": [
    "gb.run_(['overlap_title', 'temp_diff', 'comm_auth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradboost Model with removed features:  ['tfidf_distance_corpus', 'tfidf_distance_titles', 'tfidf_distance_authors']\n",
      "Gradboost model: F1 score - Training 0.971 - Validation 0.971\n"
     ]
    }
   ],
   "source": [
    "gb.run_(['tfidf_distance_corpus', 'tfidf_distance_titles','tfidf_distance_authors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "LightGBMError",
     "evalue": "Unknown token num_inc_edges in data file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-6c5b3b4b5bef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_inc_edges'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/adib/Documents/Cours/Projet/NGSA/ngsa/ngsa-kaggle/predictors/gradboost.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, lmbda)\u001b[0m\n\u001b[1;32m     14\u001b[0m         model.fit(self.features['train_data'], self.train_labels,\n\u001b[1;32m     15\u001b[0m                    \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'valid_data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                     early_stopping_rounds=50, verbose=False)\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfscore_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/adib/anaconda3/envs/py27/lib/python2.7/site-packages/lightgbm/sklearn.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    677\u001b[0m                                         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m                                         \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m                                         callbacks=callbacks)\n\u001b[0m\u001b[1;32m    680\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/adib/anaconda3/envs/py27/lib/python2.7/site-packages/lightgbm/sklearn.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    471\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/adib/anaconda3/envs/py27/lib/python2.7/site-packages/lightgbm/engine.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;31m# construct booster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mbooster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_train_data_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/adib/anaconda3/envs/py27/lib/python2.7/site-packages/lightgbm/basic.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, train_set, model_file, silent)\u001b[0m\n\u001b[1;32m   1300\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m             _safe_call(_LIB.LGBM_BoosterCreate(\n\u001b[0;32m-> 1302\u001b[0;31m                 \u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1303\u001b[0m                 \u001b[0mc_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m                 ctypes.byref(self.handle)))\n",
      "\u001b[0;32m/Users/adib/anaconda3/envs/py27/lib/python2.7/site-packages/lightgbm/basic.pyc\u001b[0m in \u001b[0;36mconstruct\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    854\u001b[0m                                 \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                                 \u001b[0mpredictor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predictor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msilent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                                 categorical_feature=self.categorical_feature, params=self.params)\n\u001b[0m\u001b[1;32m    857\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfree_raw_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/adib/anaconda3/envs/py27/lib/python2.7/site-packages/lightgbm/basic.pyc\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m(self, data, label, reference, weight, group, init_score, predictor, silent, feature_name, categorical_feature, params)\u001b[0m\n\u001b[1;32m    708\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init_from_csc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init_from_np2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/adib/anaconda3/envs/py27/lib/python2.7/site-packages/lightgbm/basic.pyc\u001b[0m in \u001b[0;36m__init_from_np2d\u001b[0;34m(self, mat, params_str, ref_dataset)\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0mc_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m             \u001b[0mref_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 772\u001b[0;31m             ctypes.byref(self.handle)))\n\u001b[0m\u001b[1;32m    773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init_from_csr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/adib/anaconda3/envs/py27/lib/python2.7/site-packages/lightgbm/basic.pyc\u001b[0m in \u001b[0;36m_safe_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \"\"\"\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBM_GetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLightGBMError\u001b[0m: Unknown token num_inc_edges in data file"
     ]
    }
   ],
   "source": [
    "gb.run(['num_inc_edges'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
